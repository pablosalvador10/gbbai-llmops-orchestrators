{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Motivation\n",
    "\n",
    "With the intention to harness the full potential of AI technologies like OpenAI's GPT-4, I recognize the need to solve critical challenges in data management and retrieval. This pursuit is driven by the goal to optimize the Retrieval Augmented Generation (RAG) process, ensuring that the AI model not only accesses but also accurately interprets and utilizes the vast knowledge stored in vector databases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùó Problem Statement\n",
    "\n",
    "\n",
    "When integrating OpenAI models, such as GPT-4, with a vector store, we encounter a unique challenge. This challenge primarily revolves around the process of Retrieval Augmented Generation (RAG). In this process, the model interacts with the vector store to retrieve specific knowledge chunks to answer a particular question from the user. This interaction presents a complex problem for the developer in terms of an effective chunking, sorting, and retrieval data strategy.\n",
    "\n",
    "**üîç The Challenges:**\n",
    "\n",
    "**Data Chunking and Sorting:**\n",
    "\n",
    "+ **Determining Optimal Chunk Size**: Deciding the appropriate size for document chunks is crucial. Too large, and the chunks may exceed the model's context window, leading to loss of information; too small, and they may lack sufficient context.\n",
    "\n",
    "+ **Effective Sorting Strategies**: Sorting these chunks for efficient retrieval is another challenge. The sorting mechanism needs to ensure that the most relevant chunks are prioritized.\n",
    "\n",
    "+ **Overlap Consideration**: Implementing overlapping chunks can be vital. It ensures continuity and context preservation, especially when dealing with long documents or complex topics.\n",
    "\n",
    "**The Impact: Fragmented Information**\n",
    "\n",
    "This fragmentation becomes particularly noticeable when similar terms appear across different sections of a document. The system may inadvertently mix up data from unrelated contexts, leading to potential confusion and misinformation. Additionally, the relevance of retrieved information can vary significantly based on how well the chunking and sorting strategy has been implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Solution\n",
    "\n",
    "Optimize chunking strategy to boost Relevant Information Retrieval metrics:\n",
    "\n",
    "The primary goal in this integration is to retrieve the most relevant and contextually accurate information. This requires a nuanced understanding of both the content's nature and the query's intent.\n",
    "\n",
    "**Importance of Chunking Strategy**: Effective chunking strategies, like creating overlapping chunks, play a critical role. They ensure that vital information isn't lost or misrepresented, and that each chunk contains a coherent piece of information that contributes meaningfully to answering the user's query.\n",
    "\n",
    "**Overlapping Chunks for Context Preservation**: Overlapping chunks can bridge the context gap between different sections of a document, ensuring that the retrieved information is not only relevant but also contextually complete, providing a more accurate and holistic response.\n",
    "\n",
    "\"Good to start a.k.a best practices\" -> implies **512 token chunks with 25% overlap.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù How-to\n",
    "\n",
    "Addressing the intricate challenges of retrieval-augmented generation (RAG) systems necessitates a thoughtful and experimental approach. Here are all the elements to enhance your chunking strategy and search:\n",
    "\n",
    "**üöÄ Implement LangChain for high-level orchestration**\n",
    "\n",
    "Use Azure Search as the vector store, incorporating an overlapping chunking strategy.\n",
    "\n",
    "**üîé Exploring Azure Cognitive Search**\n",
    "\n",
    "The query stack in Azure Cognitive Search is structured into two main layers: retrieval (L1) and ranking (L2).\n",
    "\n",
    "+ Retrieval (L1): This layer aims to quickly identify documents from a potentially massive index that meet the search criteria. It operates in three modes:\n",
    "\n",
    "    + Keyword Mode: Utilizes traditional full-text search methods, breaking content into terms through language-specific text analysis, creating inverted indexes for rapid retrieval, and scoring with the BM25 probabilistic model.\n",
    "    - Vector Mode: Converts documents into vector representations using an embedding model (like Azure Open AI's text-embedding-ada-002, or Ada-002) and performs retrieval by matching query embeddings with the closest document vectors.\n",
    "    + Hybrid Mode: Combines keyword and vector retrieval, using Reciprocal Rank Fusion (RRF) to fuse and select the best results from each method.\n",
    "\n",
    "- Ranking (L2): This layer processes a subset of the top results from L1, applying more computational power to compute high-quality relevance scores and reorder them. However, L2 can only enhance the ranking of documents identified by L1; it cannot recover missed documents. The L2 ranking, critical in RAG applications, employs multi-lingual, deep learning models adapted from Microsoft Bing to semantically rank the top 50 L1 results.\n",
    "\n",
    "Azure Cognitive Search's sophisticated approach, combining keyword and vector search in retrieval and enhancing results with advanced semantic ranking, addresses the complexities of large-scale, nuanced search requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Before you start, ensure you have a `.env` file in your project directory with the following keys:\n",
    "\n",
    "```plaintext\n",
    "OPENAI_API_KEY=****\n",
    "OPENAI_ENDPOINT=****\n",
    "AZURE_OPENAI_API_VERSION=****\n",
    "AZURE_SEARCH_SERVICE_ENDPOINT=****\n",
    "AZURE_SEARCH_ADMIN_KEY=****\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\azure-ai-gbb-solutions\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = r'C:\\Users\\pablosal\\Desktop\\azure-ai-gbb-solutions'\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 10:05:49,915 - micro - MainProcess - INFO     Loading OpenAIEmbeddings object with model text-embedding-ada-002, deployment foundational-ada, and chunk size 1 (langchain_integration.py:load_embedding_model:106)\n",
      "2023-11-23 10:05:49,923 - micro - MainProcess - INFO     OpenAIEmbeddings object created successfully. (langchain_integration.py:load_embedding_model:119)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, async_client=None, model='text-embedding-ada-002', deployment='foundational-ada', openai_api_version='2023-05-15', openai_api_base='https://ml-workspace-dev-eastus-001-aoai.openai.azure.com/', openai_api_type='azure', openai_proxy='', embedding_ctx_length=8191, openai_api_key='d050ad8b96ef4ecbb5099eece1212a91', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=16, max_retries=2, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=True, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, http_client=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the TextChunkingIndexing class from the langchain_integration module\n",
    "from src.gbb_ai.rag_utils.langchain_integration import TextChunkingIndexing\n",
    "\n",
    "# Create an instance of the TextChunkingIndexing class\n",
    "gbb_ai_client = TextChunkingIndexing()\n",
    "\n",
    "# Set up the OpenAI API client\n",
    "gbb_ai_client.setup_aoai()\n",
    "\n",
    "# Define the name of the deployment\n",
    "DEPLOYMENT_NAME = \"foundational-ada\"\n",
    "\n",
    "# Load the embedding model associated with the specified deployment\n",
    "gbb_ai_client.load_embedding_model(deployment=DEPLOYMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.36s/it]\n",
      "2023-11-23 10:05:54,174 - micro - MainProcess - INFO     Azure Cognitive Search client configured successfully. (langchain_integration.py:setup_azure_search:188)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.azuresearch.AzureSearch at 0x2211981e8b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the name of the Azure Search index\n",
    "# This is the index where your data is stored in Azure Search\n",
    "INDEX_NAME = \"index-teradyne-web\"\n",
    "\n",
    "# Set up the Azure Search client with the specified index\n",
    "# This prepares the client to interact with the Azure Search service\n",
    "gbb_ai_client.setup_azure_search(index_name=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3009, which is longer than the specified 512\n",
      "Created a chunk of size 1143, which is longer than the specified 512\n",
      "Created a chunk of size 3009, which is longer than the specified 512\n",
      "Created a chunk of size 542, which is longer than the specified 512\n",
      "Created a chunk of size 586, which is longer than the specified 512\n",
      "Created a chunk of size 3009, which is longer than the specified 512\n",
      "Created a chunk of size 562, which is longer than the specified 512\n",
      "Created a chunk of size 3009, which is longer than the specified 512\n",
      "Created a chunk of size 738, which is longer than the specified 512\n",
      "Created a chunk of size 708, which is longer than the specified 512\n",
      "Created a chunk of size 3037, which is longer than the specified 512\n",
      "Created a chunk of size 529, which is longer than the specified 512\n",
      "Created a chunk of size 762, which is longer than the specified 512\n",
      "Created a chunk of size 2065, which is longer than the specified 512\n",
      "Created a chunk of size 745, which is longer than the specified 512\n",
      "Created a chunk of size 895, which is longer than the specified 512\n",
      "Created a chunk of size 3009, which is longer than the specified 512\n",
      "Created a chunk of size 1706, which is longer than the specified 512\n",
      "Created a chunk of size 3009, which is longer than the specified 512\n"
     ]
    }
   ],
   "source": [
    "# Scrap web and chuck files intp sentences \n",
    "# Define the URLs of the web pages to scrape\n",
    "\n",
    "urls = [\n",
    "    \"https://www.teradyne.com/products/tps-converter-studio/\",\n",
    "    \"https://www.teradyne.com/resources/ig-xl-software/\",\n",
    "    \"https://www.teradyne.com/device-programming-solutions/\",\n",
    "    \"https://www.teradyne.com/products/ultraflex/\",\n",
    "    \"https://www.teradyne.com/test-program-development-and-debug-solutions/\",\n",
    "    \"https://www.teradyne.com/products/ultraflexplus/\",\n",
    "    \"https://investors.teradyne.com/news-releases/news-release-details/teradyne-introduces-ig-xl-real-time-audit-tool-drive-higher-test\"\n",
    "]\n",
    "\n",
    "# Set the chunk size and overlap size for splitting the text\n",
    "CHUNK_SIZE = 512\n",
    "OVERLAP_SIZE = 128\n",
    "\n",
    "# Scrape the web pages, split the text into chunks, and store the chunks\n",
    "# The text is split into chunks of size CHUNK_SIZE, with an overlap of OVERLAP_SIZE between consecutive chunks\n",
    "text_chuncked = gbb_ai_client.scrape_web_text_and_split_by_character(urls=urls, chunk_size=CHUNK_SIZE, chunk_overlap=OVERLAP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='ProductsApplicationsServicesSupportCompanyDefense & AerospaceDigital/Mixed Signal TestingMemory TestingPrecision Power & AnalogProduction Board TestingRoboticsStorage TestSystem Level TestWireless TestingDefense & AerospaceMemory TestingProduction Board TestingRoboticsSemiconductor TestingStorage TestingSystem Level TestingWireless TestingApplications SupportDefense & Aerospace ServicesDevice Interface SolutionsEngineering ServicesPBT Parts ServicesSoftware SolutionseKnowledgeArtwork Packages Account RequestTrainingTUGxAbout UsBlogCareersContact UsCorporate Social ResponsibilityGrant ProgramInvestor RelationsManagement TeamNewsroomInstrumentationAnalog TestBus TestDigital TestOptical Switching & Power ManagementReconfigurable Instruments & SubsystemsSupportLife-cycle Support SolutionsTest SystemsGuardian‚Ñ¢Spectrum BT‚Ñ¢Spectrum HS‚Ñ¢Spectrum RF SystemsSpectrum-9100‚Ñ¢IP750ExJ750Ex-HD FamilyUltraFLEXUltraFLEXplusMagnum 2Magnum EPICMagnum VMagnum VUxETS-364ETS-800ETS-88Lemsys ProductsInline Test SolutionsOffline Test SolutionsSmart Factory SolutionsTestStation Product FamilyAutonomous Mobile RobotsCollaborative RobotsSaturnTitanJ750LitePoint Wireless Test ProductsTitanUltraFLEXProductsApplicationsServicesSupportCompanyTUGxeKnowledgeLanguageChinese SimplifiedJapaneseSearchBackProductsDefense & AerospaceDigital/Mixed Signal TestingRoboticsPrecision Power & AnalogMemory TestingProduction Board TestingSystem Level TestStorage TestWireless TestingBackDefense & AerospaceInstrumentationSupportTest SystemsBackInstrumentationReconfigurable Instruments & SubsystemsDigital TestBus TestAnalog TestOptical Switching & Power ManagementBackSupportLife-cycle Support SolutionsBackTest SystemsGuardian‚Ñ¢Spectrum-9100‚Ñ¢Spectrum BT‚Ñ¢Spectrum HS‚Ñ¢Spectrum RF SystemsBackDigital/Mixed Signal TestingIP750ExJ750Ex-HD FamilyUltraFLEXUltraFLEXplusBackAutonomous Mobile RobotsCollaborative RobotsBackPrecision Power & AnalogETS-800ETS-88ETS-364Lemsys ProductsBackMemory TestingMagnum 2Magnum EPICMagnum VMagnum VUxBackProduction Board TestingOffline Test SolutionsInline Test SolutionsSmart Factory SolutionsTestStation Product FamilyBackSystem Level TestTitanBackSaturnBackJ750UltraFLEXTitanLitePoint Wireless Test ProductsBackApplicationsDefense & AerospaceRoboticsMemory TestingProduction Board TestingSemiconductor TestingStorage TestingSystem Level TestingWireless TestingBackServicesApplications SupportDevice Interface SolutionsEngineering ServicesSoftware SolutionsPBT Parts ServicesDefense & Aerospace ServicesBackSupporteKnowledgeArtwork Packages Account RequestTrainingTUGxBackCompanyInvestor RelationsNewsroomBlogGrant ProgramCorporate Social ResponsibilityContact UsCareersAbout UsManagement TeamBackAvionics Test SolutionsInstrumentsSoftwareSystemsSubsystemsBackAvionics Test SolutionsAvionics/Test InstrumentationBackInstrumentsAi-SeriesBi-SeriesDi-SeriesBackSoftwareLASAR SoftwareTestStudio SoftwareTPS Converter StudioBackSystemsSpectrum-9100Spectrum BTSpectrum HSBackSubsystemsHigh Speed SubsystemVERTA', metadata={'source': 'https://www.teradyne.com/products/tps-converter-studio/', 'title': 'TPS Converter Studio | Teradyne', 'description': 'Test program solution for conversion of legacy L-Series code to Teradyne digital instruments and Spectrum-9100 systems', 'language': 'en-US'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chuncked[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.97it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.65it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.20it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.07it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.38it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.46it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.30it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.87it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.13it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.22it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.69it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.98it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.85it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.78it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.62it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.31it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.10it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.45it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.75it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.46it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.94it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.06it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.80it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.46it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.18it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.01it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.74it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.63it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.83it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.27it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.74it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.93it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.90it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.27it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.27it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.57it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.19it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.09it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.62it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.47it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.79it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.50it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.03it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.02it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.75it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.74it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.09it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.22it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.02it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.07it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.20it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.71it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.09it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.04it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.56it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.75it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.60it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.85it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.03it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.01it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed the chunks and index them in Azure Search\n",
    "# This function converts the text chunks into vector embeddings and stores them in the Azure Search index\n",
    "gbb_ai_client.embed_and_index(text_chuncked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-your-own-copilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
